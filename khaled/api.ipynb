{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Stockholm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to location_2163258.json\n",
      "Data saved to location_6229.json\n",
      "Data saved to location_270749.json\n",
      "Data saved to location_7947.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "\n",
    "country_code = \"SE\"\n",
    "city = \"Stockholm\"\n",
    "location_ids = [\"2163258\", \"6229\", \"270749\", \"7947\"]   #Torkel, Svea, sundbyberg, Stockholm E4/E20 Lil\n",
    "\n",
    "# API key\n",
    "api_key = \"7b2fbb569507ae14141d3de0ff76044999ae3859816024ab9d2978c83bc3d804\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"x-api-key\": api_key\n",
    "}\n",
    "\n",
    "# loop for the location\n",
    "for location_id in location_ids:\n",
    "    \n",
    "    url = f\"https://api.openaq.org/v2/locations/{location_id}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Save the data \n",
    "        filename = f\"location_{location_id}.json\"\n",
    "        with open(filename, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "        \n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(f'Error for location ID {location_id}: {response.status_code}, {response.text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sveav√§gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combined all Json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Construct the full path dynamically\n",
    "directory = os.path.join(os.getcwd())\n",
    "# List to hold all extracted data\n",
    "all_data = []\n",
    "\n",
    "# Loop through each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        with open(filepath, 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "        \n",
    "        # Loop through each result in the current file\n",
    "        for result in data['results']:\n",
    "            location_name = result['name']\n",
    "            meter_id = result['id']\n",
    "            lat = result['coordinates']['latitude']\n",
    "            lon = result['coordinates']['longitude']\n",
    "\n",
    "            # Extract the 'day' and 'time' \n",
    "            last_updated = result['lastUpdated']\n",
    "            day, time = last_updated.split('T')\n",
    "            time = time.split('+')[0]  # Remove the timezone if present\n",
    "\n",
    "            # Initialize dictionary with default None for each pollutant\n",
    "            parameter_values = {\n",
    "                \"meter ID\": meter_id,\n",
    "                \"location name\": location_name,\n",
    "                \"lat\": lat,\n",
    "                \"lon\": lon,\n",
    "                \"day\": day,\n",
    "                \"time\": time,\n",
    "                \"pm2.5\": None,\n",
    "                \"pm10\": None,\n",
    "                \"so2\": None,\n",
    "                \"no\": None,\n",
    "                \"o3\": None\n",
    "            }\n",
    "\n",
    "            # Map JSON parameter names to desired column names\n",
    "            param_map = {\n",
    "                \"pm25\": \"pm2.5\",\n",
    "                \"pm10\": \"pm10\",\n",
    "                \"so2\": \"so2\",\n",
    "                \"no2\": \"no\",\n",
    "                \"o3\": \"o3\"\n",
    "            }\n",
    "\n",
    "            # Loop through parameters to find specific pollutants\n",
    "            for parameter in result['parameters']:\n",
    "                parameter_name = parameter['parameter']\n",
    "                last_value = parameter['lastValue']\n",
    "\n",
    "                # Add the parameter's last value to the dictionary if it matches\n",
    "                if parameter_name in param_map:\n",
    "                    parameter_values[param_map[parameter_name]] = last_value\n",
    "\n",
    "            # Append the dictionary to the all_data list\n",
    "            all_data.append(parameter_values)\n",
    "\n",
    "# Convert the combined data to a DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "# Reorder columns to match desired order\n",
    "df = df[[\"meter ID\", \"location name\", \"lat\", \"lon\", \"day\", \"time\", \"pm2.5\", \"pm10\", \"so2\", \"no\", \"o3\"]]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('Stockholm_combined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "historic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to location_4318.json\n",
      "Data saved to location_154.json\n",
      "Data saved to location_4767.json\n",
      "Data saved to location_7529.json\n",
      "Data saved to location_4593.json\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "\n",
    "country_code = \"SE\"\n",
    "city = \"Stockholm\"\n",
    "#location_ids = [\"2163258\", \"6229\", \"270749\"]   #Torkel, Svea, sundbyberg\n",
    "location_ids = ['4318', '154', '4767', '7529', '4593']\n",
    "\n",
    "# API key\n",
    "api_key = \"7b2fbb569507ae14141d3de0ff76044999ae3859816024ab9d2978c83bc3d804\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"x-api-key\": api_key\n",
    "}\n",
    "\n",
    "# loop for the location\n",
    "for location_id in location_ids:\n",
    "    \n",
    "    url = f\"https://api.openaq.org/v1/measurements?date_from=2023-01-01&limit=10000&page=1&offset=0&sort=desc&radius=1000&location_id={location_id}&order_by=datetime\"\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        # Save the data \n",
    "        filename = f\"location_{location_id}.json\"\n",
    "        with open(filename, 'w') as json_file:\n",
    "            json.dump(data, json_file, indent=4)\n",
    "        \n",
    "        print(f\"Data saved to {filename}\")\n",
    "    else:\n",
    "        print(f'Error for location ID {location_id}: {response.status_code}, {response.text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                location name       lat        lon         day  \\\n",
      "0      London Marylebone Road  51.52253  -0.154611  2024-09-04   \n",
      "1      London Marylebone Road  51.52253  -0.154611  2024-09-04   \n",
      "2      London Marylebone Road  51.52253  -0.154611  2024-09-04   \n",
      "3      London Marylebone Road  51.52253  -0.154611  2024-09-04   \n",
      "4      London Marylebone Road  51.52253  -0.154611  2024-09-04   \n",
      "...                       ...       ...        ...         ...   \n",
      "12311                 Arenula  41.89402  12.475368  2024-05-19   \n",
      "12312                 Arenula  41.89402  12.475368  2024-05-19   \n",
      "12313                 Arenula  41.89402  12.475368  2024-05-19   \n",
      "12314                 Arenula  41.89402  12.475368  2024-05-19   \n",
      "12315                 Arenula  41.89402  12.475368  2024-05-19   \n",
      "\n",
      "                 time  pm2.5  pm10  so2   no2    o3  co   no   nox  \n",
      "0      09:00:00+00:00    8.0  12.0  1.0  16.0  19.0 NaN  NaN   NaN  \n",
      "1      08:00:00+00:00    8.0  13.0  NaN  14.5  26.2 NaN  NaN   NaN  \n",
      "2      07:00:00+00:00    NaN   NaN  NaN  18.9   NaN NaN  NaN   NaN  \n",
      "3      06:00:00+00:00    NaN   NaN  0.7  21.5   NaN NaN  NaN   NaN  \n",
      "4      05:00:00+00:00    NaN   NaN  0.7  18.8   NaN NaN  NaN   NaN  \n",
      "...               ...    ...   ...  ...   ...   ...  ..  ...   ...  \n",
      "12311  19:00:00+00:00    NaN   NaN  NaN  13.0  67.0 NaN  2.0  17.0  \n",
      "12312  18:00:00+00:00    NaN   NaN  NaN  11.0  66.0 NaN  1.0  13.0  \n",
      "12313  17:00:00+00:00    NaN   NaN  NaN  10.0  61.0 NaN  1.0  12.0  \n",
      "12314  16:00:00+00:00    NaN   NaN  NaN  11.0  50.0 NaN  2.0  15.0  \n",
      "12315  15:00:00+00:00    NaN   NaN  NaN  10.0  61.0 NaN  1.0  12.0  \n",
      "\n",
      "[12316 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Construct the full path dynamically\n",
    "directory = os.path.join(os.getcwd())\n",
    "# List to hold all extracted data\n",
    "all_data = []\n",
    "\n",
    "\n",
    "\n",
    "# Loop through each file in the directory\n",
    "param_map = {\n",
    "    \"pm25\": \"pm2.5\",\n",
    "    \"pm10\": \"pm10\",\n",
    "    \"so2\": \"so2\",\n",
    "    \"no2\": \"no2\",\n",
    "    \"o3\": \"o3\",\n",
    "    \"co\": \"co\",\n",
    "    \"no\": \"no\",\n",
    "    \"nox\": \"nox\"\n",
    "    \n",
    "}\n",
    "\n",
    "# Initialize a dictionary to collect data\n",
    "all_data = {}\n",
    "\n",
    "# Loop through each JSON file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        \n",
    "        with open(filepath, 'r') as json_file:\n",
    "            results = json.load(json_file)['results']\n",
    "        \n",
    "        # Loop through each result in the JSON file\n",
    "        for result in results:\n",
    "            day, time = result['date']['utc'].split(\"T\")\n",
    "            location = result['location']\n",
    "            lat = result['coordinates']['latitude']\n",
    "            lon = result['coordinates']['longitude']\n",
    "            param = result['parameter']\n",
    "\n",
    "            # Use a tuple as a unique key for each location, day, and time\n",
    "            key = (location, day, time)\n",
    "\n",
    "            # If the key doesn't exist in all_data, initialize the entry\n",
    "            if key not in all_data:\n",
    "                all_data[key] = {\n",
    "                    \"location name\": location,\n",
    "                    \"lat\": lat,\n",
    "                    \"lon\": lon,\n",
    "                    \"day\": day,\n",
    "                    \"time\": time,\n",
    "                    \"pm2.5\": None,\n",
    "                    \"pm10\": None,\n",
    "                    \"so2\": None,\n",
    "                    \"no2\": None,\n",
    "                    \"o3\": None,\n",
    "                    \"co\": None,\n",
    "                    \"no\": None,\n",
    "                    \"nox\": None\n",
    "                    \n",
    "                }\n",
    "\n",
    "            # Set the appropriate value in the existing entry\n",
    "                       # Safeguard against any parameters not in the param_map\n",
    "            if param in param_map:\n",
    "                # Set the appropriate value in the existing entry\n",
    "                all_data[key][param_map[param]] = result['value']\n",
    "            else:\n",
    "                print(f\"Warning: Parameter '{param}' is not in param_map and was skipped.\")\n",
    "            \n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(all_data.values())\n",
    "\n",
    "# Reorder columns\n",
    "df = df[[\"location name\", \"lat\", \"lon\", \"day\", \"time\", \"pm2.5\", \"pm10\", \"so2\", \"no2\", \"o3\", \"co\",\"no\", \"nox\"]]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('historic_combined.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            location name       lat       lon         day            time  \\\n",
      "0  London Marylebone Road  51.52253 -0.154611  2024-09-04  09:00:00+00:00   \n",
      "1  London Marylebone Road  51.52253 -0.154611  2024-09-04  08:00:00+00:00   \n",
      "2  London Marylebone Road  51.52253 -0.154611  2024-09-04  07:00:00+00:00   \n",
      "3  London Marylebone Road  51.52253 -0.154611  2024-09-04  06:00:00+00:00   \n",
      "4  London Marylebone Road  51.52253 -0.154611  2024-09-04  05:00:00+00:00   \n",
      "\n",
      "   pm2.5  pm10  so2   no2    o3  co  no  nox  \n",
      "0    8.0  12.0  1.0  16.0  19.0 NaN NaN  NaN  \n",
      "1    8.0  13.0  NaN  14.5  26.2 NaN NaN  NaN  \n",
      "2    NaN   NaN  NaN  18.9   NaN NaN NaN  NaN  \n",
      "3    NaN   NaN  0.7  21.5   NaN NaN NaN  NaN  \n",
      "4    NaN   NaN  0.7  18.8   NaN NaN NaN  NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_from_csv = pd.read_csv('historic_combined.csv')\n",
    "print(df_from_csv.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
